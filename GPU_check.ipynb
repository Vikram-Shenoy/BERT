{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"CCCVA, MANOVA, my black hen. Comments on repeated measures. Nikolsky sign page from notable contributors to the knowledge of dermatology.\n",
    "[Obesity as a concomitant cause in the complex etiology of arteriosclerosis ]. Tropical mixtures of star tree metrics.\n",
    "We study three metrics that can be realized as a mixture of two-star tree metrics.\n",
    "We prove that the only trees admitting such a decomposition are the ones coming from a tree with at most one internal edge, and whose weight satisfies certain linear inequalities.\n",
    "We also characterize the fibers of the corresponding mixture map. In addition, we discuss the general framework of tropical secant varieties and we interpret our results within this setting.\n",
    "Finally, we show that the set of tree metric ranks of metrics on $ n $ taxa is unbounded. \n",
    "Comment: 19 pages, 5 figures. Major revision of the exposition following suggestions by the referee.\n",
    "To appear in Annals of Combinatoric Pasteurellosis in japanese quail (Coturnix coturnix japonica) caused by Pasteurella multocida multocida A:4. \n",
    "NUTRITIONAL WELL-BEING IN THE U.S.A.Counseling professional nurses. Evaluation of transdermal penetration enhancers using a novel skin alternative . \n",
    "A novel alternative to animal skin models was developed in order to aid in the screening of transdermal penetration enhancer . \n",
    "The skin alternative consists of a dermal layer containing human fibroblasts dispersed in a collagen matrix and an epidermal layer of differentiated and stratified human keratinocytes.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(test_sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer.encode(test_sentence)\n",
    "input_ids = torch.tensor([tokenized_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-6.7886e-02, -2.8985e-01, -6.6888e-01,  ..., -1.9736e-01,\n",
       "           1.4356e-01, -1.5104e-01],\n",
       "         [-4.6176e-01, -2.7889e-02,  6.3926e-01,  ...,  2.3299e-02,\n",
       "           5.3325e-01, -8.4372e-02],\n",
       "         [-1.6964e-01, -5.8373e-01,  7.4835e-01,  ..., -6.8798e-01,\n",
       "          -7.1269e-02, -5.7822e-01],\n",
       "         ...,\n",
       "         [ 1.7092e-01, -3.0000e-01,  6.0852e-01,  ..., -2.2250e-01,\n",
       "          -5.7188e-01, -7.9723e-01],\n",
       "         [-1.9165e-01, -4.8469e-01, -2.7576e-01,  ..., -9.3298e-02,\n",
       "           9.5298e-02, -4.6595e-01],\n",
       "         [ 2.1846e-02, -9.9547e-01, -1.5670e+00,  ...,  2.5161e-01,\n",
       "          -1.5230e-03,  4.6059e-01]]]), pooler_output=tensor([[-0.0114, -0.0147,  0.9273, -0.9999,  0.9987,  0.8481, -0.0264,  0.1929,\n",
       "          0.2180,  0.0158,  0.9947,  0.9978, -0.9518, -0.7978, -0.3652, -0.3834,\n",
       "          0.9997,  0.1202, -0.9864, -0.3124,  0.0133, -0.8610, -0.0061,  0.9936,\n",
       "          0.0535, -0.2467,  0.9996,  0.9822, -0.0218,  0.0825, -0.1602, -0.9967,\n",
       "          0.9787, -0.9966,  0.1127,  0.0736,  0.0324, -0.0345,  0.7261, -0.9876,\n",
       "          0.1097, -0.4369,  0.0607, -0.0298,  0.9978, -0.0523, -0.0650,  0.0666,\n",
       "         -0.1527,  0.9137,  0.3002,  0.9891, -0.9982,  0.9963,  0.9996,  0.1699,\n",
       "          0.9997, -0.0844, -0.4381, -0.0312,  0.0501, -0.0035, -0.2841, -0.0949,\n",
       "         -0.0544,  0.0229, -0.9802,  0.1278,  0.0633,  0.0970, -0.2443,  0.0748,\n",
       "          0.9683,  0.1852,  0.0443, -0.1210,  0.0535, -0.8596,  0.9969,  0.9948,\n",
       "          0.8377, -0.9960,  0.9970, -0.0213,  0.0481,  0.0167,  0.5239, -0.9996,\n",
       "         -0.0984, -0.0278,  0.9983, -0.9956, -0.1053, -0.9683,  0.9916,  0.0232,\n",
       "          0.0027,  0.0679,  0.9987, -0.3987,  0.0053,  0.9989, -0.0975,  0.8349,\n",
       "          0.8902,  0.0528, -0.1274, -0.9461, -0.9348, -0.0896, -0.5772,  0.2638,\n",
       "          0.0553,  0.0921,  0.9642, -0.9457,  0.9997, -0.2492,  0.0076,  0.9788,\n",
       "          0.0590,  0.9804,  0.9999,  0.1341,  0.5900,  0.0254, -0.0994,  0.9942,\n",
       "         -0.0185, -0.1210,  0.1225, -0.9998, -0.9706,  0.9999, -0.0512,  0.9968,\n",
       "         -0.9998,  0.9925, -0.9174, -0.4539, -0.0935, -0.0362, -0.9964,  0.3036,\n",
       "          0.2430,  0.1142, -0.9953, -0.7242,  0.0354, -0.3180, -0.0229,  0.1558,\n",
       "          0.0435,  0.9299,  0.9977,  0.9965,  0.9973, -0.0485,  0.5338,  0.9869,\n",
       "          0.9939, -0.9999,  0.0890, -0.9747,  0.9366,  0.9893, -0.0188,  0.6795,\n",
       "          0.9998,  0.1465, -0.0654, -0.3147, -0.0218, -0.4012, -0.0382, -0.1031,\n",
       "          0.0411,  0.9941, -0.9991,  0.7345,  0.1191,  0.1580,  0.1691,  0.7519,\n",
       "         -0.9998, -0.7773, -0.9971,  0.0958, -0.2358, -0.1478,  0.0178,  0.0988,\n",
       "         -0.5447,  0.0780, -0.7509, -0.0573,  0.9646, -0.1799,  0.9962,  0.3021,\n",
       "         -0.9999,  0.5510,  0.9960, -0.3368,  0.0083, -0.0432, -0.0417,  0.1730,\n",
       "          0.2061, -0.9709, -0.8450, -0.0794,  0.0282,  0.2141,  0.9679, -0.0976,\n",
       "          0.0042,  0.0800, -0.0252,  0.9982, -0.9997, -0.0622,  0.1342, -0.9998,\n",
       "         -0.9996,  0.9807,  0.0127,  0.1610,  0.0169, -0.4497, -0.0689,  0.9993,\n",
       "          0.9970,  0.0243,  0.0518, -0.9891,  0.5001,  0.0571, -0.9940, -0.0487,\n",
       "         -0.1578, -0.1011,  0.0751, -0.9338, -0.0027,  0.3378, -0.9946,  0.2344,\n",
       "          0.0276, -0.7177,  0.1919, -0.4765, -0.9261,  0.9999, -0.9866,  0.9899,\n",
       "          0.9537, -0.9998,  0.1581, -0.3895,  0.0492, -0.9900,  0.0719, -0.1040,\n",
       "         -0.2263, -0.0145,  0.9998,  0.3963, -0.8218,  0.0364, -0.9966,  0.2319,\n",
       "          0.0954,  0.9998,  0.4032,  0.9837,  0.4318,  0.7412, -0.9971, -0.9973,\n",
       "          0.9833,  0.8953, -0.9999, -0.1206,  0.9968,  0.3717, -0.0416, -0.9889,\n",
       "         -0.8281, -0.9999, -0.1022,  0.1336,  0.0927,  0.7375, -0.0258,  0.1323,\n",
       "          0.9978,  0.9844,  0.0735, -0.0684,  0.0088, -0.9981, -0.8853,  0.0840,\n",
       "         -0.1776, -0.9597,  0.9992, -0.9972,  0.9962,  0.9950,  0.2400, -0.0582,\n",
       "         -0.1221, -0.9971, -0.0334,  0.9840,  0.8083, -0.0705,  0.0488,  0.9765,\n",
       "         -0.0340,  0.0265,  0.0298, -0.0101, -0.0728,  0.0838,  0.9832, -0.4252,\n",
       "         -0.9997,  0.9843,  0.0799,  0.1152, -0.9534,  0.1268,  0.9998, -0.0422,\n",
       "         -0.0028,  0.0637, -0.1643, -0.2211,  0.0136, -0.9984, -0.0044, -0.8623,\n",
       "          0.9834, -0.9932,  0.9941, -0.0886,  0.9423,  0.0166,  0.9862, -0.9958,\n",
       "          0.0094,  0.2489, -0.9962, -0.0404,  0.9883,  0.9690,  0.9835, -0.2566,\n",
       "         -0.1059, -0.1486,  0.1067, -0.9964,  0.0339,  0.3498, -0.2050,  0.9868,\n",
       "          0.6938, -0.0185, -0.3420, -0.9973,  0.1277, -0.4600, -0.8262,  0.1724,\n",
       "         -0.9817,  0.2026, -0.0801, -0.1443,  0.9971, -0.0734, -0.8890,  0.9764,\n",
       "          0.3482,  0.9989, -0.9997,  0.0477,  0.9843,  0.0551, -0.7524,  0.0537,\n",
       "         -0.3481, -0.9443, -0.0971, -0.9994, -0.1064,  0.0149,  0.0174, -0.1459,\n",
       "         -0.0864,  0.1084,  0.9983, -0.0785,  0.1975, -0.3243, -0.1038, -0.0225,\n",
       "         -0.0481, -0.0755,  0.0553,  0.1021,  0.0317,  0.8988,  0.2940,  0.9812,\n",
       "         -0.0024, -0.9958,  0.5543, -0.9382, -0.9767,  0.0526, -0.9941,  0.9997,\n",
       "          0.8816, -0.9067, -0.3210, -0.9910, -0.9730,  0.9781, -0.0449, -0.0839,\n",
       "         -0.1243,  0.6372, -0.1766, -0.1728, -0.0296,  0.0642, -0.1375, -0.0826,\n",
       "          0.1287, -0.9937,  0.5173,  0.9500, -0.9362, -0.8767, -0.9878,  0.4035,\n",
       "          0.0981,  0.0647,  0.8115, -0.0353, -0.0149, -0.9418,  0.6651, -0.8044,\n",
       "          0.0552, -0.0698,  0.0875,  0.9645, -0.3047,  0.0699, -0.0370, -0.9723,\n",
       "          0.9966, -0.9985,  0.0663, -0.9789, -0.1361,  0.6474, -0.9920, -0.0277,\n",
       "          0.8366,  0.9510,  0.9942, -0.0900,  0.0119, -0.2430,  0.0161, -0.9655,\n",
       "          0.7535, -0.2764,  0.3060, -0.0397,  0.9655,  0.9092, -0.8627, -0.9973,\n",
       "          0.9873, -0.0167,  0.1193,  0.1107, -0.0269, -0.1305,  0.0588, -0.9997,\n",
       "         -0.9947,  0.9998,  0.9182, -0.1306,  0.9319,  0.9446,  0.1854, -0.0881,\n",
       "         -0.9907, -0.7773,  0.1429, -0.0567, -0.9980,  0.8766, -0.9798, -0.0857,\n",
       "          0.0210,  0.9977,  0.9996,  0.1376, -0.9981, -0.9871, -0.9193, -0.0377,\n",
       "          0.9247, -0.0109,  0.0770, -0.1318, -0.3548,  0.9594,  0.5146,  0.0987,\n",
       "         -0.8901,  0.9995, -0.1672, -0.9993,  0.9628, -0.9958,  0.6571,  0.1056,\n",
       "          0.9926, -0.2171,  0.5949,  0.9952, -0.9936,  0.9086, -0.9863,  0.4057,\n",
       "          0.9996, -0.9998, -0.1493, -0.9999, -0.9961,  0.1664, -0.0988, -0.0706,\n",
       "          0.9900, -0.9999, -0.9983, -0.0300, -0.9976, -0.7764,  0.9958, -0.0925,\n",
       "          0.9137, -0.0353,  0.0467, -0.0294,  0.7999,  0.9954,  0.1014, -0.0352,\n",
       "         -0.9997,  0.9836, -0.2014,  0.1221,  0.9997,  0.0405,  0.0309,  0.0249,\n",
       "         -0.9996, -0.2437,  0.2617, -0.4099,  0.9782, -0.0251,  0.0151,  0.0899,\n",
       "          0.0763, -0.9908,  0.0223, -0.9901,  0.9983, -0.9968,  0.0049, -0.0296,\n",
       "          0.2409,  0.1692,  0.9841,  0.9999, -0.9565, -0.1052,  0.9984, -0.0343,\n",
       "          0.9309, -0.9999, -0.0896,  0.2825,  0.0335,  0.9993,  0.0448,  0.1328,\n",
       "          0.5959, -0.9997, -0.9982, -0.0586, -0.0546, -0.0293, -0.9997, -0.0013,\n",
       "          0.9712,  0.0712, -0.9999,  0.1169, -0.9999,  0.1158,  0.9912,  0.4390,\n",
       "          0.9984,  0.0895, -0.0015,  0.0450, -0.9991, -0.9233, -0.0459,  0.1804,\n",
       "         -0.9337,  0.1008,  0.0450, -0.0467, -0.8741,  0.0136,  0.9028,  0.1209,\n",
       "         -0.2977, -0.2917,  0.0486, -0.9878, -0.1874,  0.0788,  0.9152, -0.9865,\n",
       "         -0.1043, -0.3796,  0.9850, -0.9999, -0.0772, -0.9979, -0.1361,  0.0495,\n",
       "         -0.0769,  0.1449,  0.0208,  0.4213, -0.9964,  0.9999, -0.9999, -0.9992,\n",
       "          0.9995, -0.0850, -0.9992,  0.0259,  0.0253, -0.0476, -0.1037,  0.1640,\n",
       "          0.4319, -0.0740, -0.9640, -0.3278, -0.7141,  0.0809, -0.0894, -0.1147,\n",
       "         -0.9988,  0.9999,  0.9998,  0.9981, -0.9987,  0.1541,  0.1780,  0.9997,\n",
       "          0.0945, -0.0887,  0.9976,  0.9782, -0.0127,  0.9247, -0.0486,  0.0148,\n",
       "          0.0696, -0.0551, -0.5922, -0.9986, -0.1165, -0.9956, -0.9531,  0.9313,\n",
       "          0.1214,  0.9981,  0.0945, -0.0589, -0.2944,  0.9972, -0.9937, -0.1217,\n",
       "         -0.9779, -0.0353, -0.9977, -0.9975, -0.0691, -0.0716, -0.9901,  0.3034,\n",
       "          0.0349, -0.9857,  0.9882, -0.9954, -0.9963, -0.9850, -0.4469,  0.0069,\n",
       "          0.6944,  0.9758, -0.6792,  0.9988, -0.6776,  0.8280, -0.1483, -0.1681,\n",
       "         -0.0507, -0.9879, -0.8576, -0.9996,  0.1636, -0.9992,  0.1672,  0.9994,\n",
       "          0.9998, -0.9824, -0.9999,  0.9845, -0.3306,  0.9996,  0.0265, -0.9931,\n",
       "         -0.9963, -0.0402, -0.0128,  0.9992, -0.1566,  0.7896,  0.1593,  0.0895,\n",
       "         -0.0449,  0.1303, -0.0871, -0.1202, -0.0108,  0.9843, -0.1009,  0.9998]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6244\\4244915882.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mnew_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mnew_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mnew_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tag_values' is not defined"
     ]
    }
   ],
   "source": [
    "# join bpe split tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_labels = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(tag_values[label_idx])\n",
    "        new_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb7935b20b1350c43bf64077ed6a04b20dae5a2fec5d0927cb7fd3126576106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
