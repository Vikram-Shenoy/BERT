{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "med_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "med_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False) \n",
    "bert_model = BertForTokenClassification.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"CCCVA, MANOVA, my black hen. Comments on repeated measures. Nikolsky sign page from notable contributors to the knowledge of dermatology.\n",
    "[Obesity as a concomitant cause in the complex etiology of arteriosclerosis ]. Tropical mixtures of star tree metrics.\n",
    "We study three metrics that can be realized as a mixture of two-star tree metrics.\n",
    "We prove that the only trees admitting such a decomposition are the ones coming from a tree with at most one internal edge, and whose weight satisfies certain linear inequalities.\n",
    "We also characterize the fibers of the corresponding mixture map. In addition, we discuss the general framework of tropical secant varieties and we interpret our results within this setting.\n",
    "Finally, we show that the set of tree metric ranks of metrics on $ n $ taxa is unbounded. \n",
    "Comment: 19 pages, 5 figures. Major revision of the exposition following suggestions by the referee.\n",
    "To appear in Annals of Combinatoric Pasteurellosis in japanese quail (Coturnix coturnix japonica) caused by Pasteurella multocida multocida A:4. \n",
    "NUTRITIONAL WELL-BEING IN THE U.S.A.Counseling professional nurses. Evaluation of transdermal penetration enhancers using a novel skin alternative . \n",
    "A novel alternative to animal skin models was developed in order to aid in the screening of transdermal penetration enhancer . \n",
    "The skin alternative consists of a dermal layer containing human fibroblasts dispersed in a collagen matrix and an epidermal layer of differentiated and stratified human keratinocytes.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT         Med_BERT    \n",
      "----         -------     \n",
      "CC           cc          \n",
      "##C          ##c         \n",
      "##VA         ##va        \n",
      ",            ,           \n",
      "MA           man         \n",
      "##N          ##ova       \n",
      "##O          ,           \n",
      "##VA         my          \n",
      ",            black       \n",
      "my           he          \n",
      "black        ##n         \n",
      "he           .           \n",
      "##n          comments    \n",
      ".            on          \n",
      "Co           repeated    \n",
      "##mme        measures    \n",
      "##nts        .           \n",
      "on           ni          \n",
      "repeated     ##ko        \n",
      "measures     ##ls        \n",
      ".            ##ky        \n",
      "Nik          sign        \n",
      "##ols        page        \n",
      "##ky         from        \n",
      "sign         notable     \n",
      "page         contributors\n",
      "from         to          \n",
      "notable      the         \n",
      "contributors knowledge   \n",
      "to           of          \n",
      "the          der         \n",
      "knowledge    ##mat       \n",
      "of           ##ology     \n",
      "der          .           \n",
      "##mat        [           \n",
      "##ology      o           \n",
      ".            ##besity    \n",
      "[            as          \n",
      "O            a           \n",
      "##besity     con         \n",
      "as           ##com       \n",
      "a            ##ita       \n",
      "con          ##nt        \n",
      "##com        cause       \n",
      "##ita        in          \n",
      "##nt         the         \n",
      "cause        complex     \n",
      "in           et          \n",
      "the          ##iology    \n",
      "complex      of          \n",
      "et           art         \n",
      "##iology     ##eri       \n",
      "of           ##os        \n",
      "art          ##cle       \n",
      "##eri        ##rosis     \n",
      "##os         ]           \n",
      "##cle        .           \n",
      "##rosis      tropical    \n",
      "]            mixture     \n",
      ".            ##s         \n",
      "Tropical     of          \n",
      "mixture      star        \n",
      "##s          tree        \n",
      "of           metric      \n",
      "star         ##s         \n",
      "tree         .           \n",
      "metric       we          \n",
      "##s          study       \n",
      ".            three       \n",
      "We           metric      \n",
      "study        ##s         \n",
      "three        that        \n",
      "metric       can         \n",
      "##s          be          \n",
      "that         realized    \n",
      "can          as          \n",
      "be           a           \n",
      "realized     mixture     \n",
      "as           of          \n",
      "a            two         \n",
      "mixture      -           \n",
      "of           star        \n",
      "two          tree        \n",
      "-            metric      \n",
      "star         ##s         \n",
      "tree         .           \n",
      "metric       we          \n",
      "##s          prove       \n",
      ".            that        \n",
      "We           the         \n",
      "prove        only        \n",
      "that         trees       \n",
      "the          admitting   \n",
      "only         such        \n",
      "trees        a           \n",
      "admitting    decomposition\n",
      "such         are         \n",
      "a            the         \n",
      "decomposition ones        \n",
      "are          coming      \n",
      "the          from        \n",
      "ones         a           \n",
      "coming       tree        \n",
      "from         with        \n",
      "a            at          \n",
      "tree         most        \n",
      "with         one         \n",
      "at           internal    \n",
      "most         edge        \n",
      "one          ,           \n",
      "internal     and         \n",
      "edge         whose       \n",
      ",            weight      \n",
      "and          sat         \n",
      "whose        ##is        \n",
      "weight       ##fies      \n",
      "sat          certain     \n",
      "##is         linear      \n",
      "##fies       in          \n",
      "certain      ##e         \n",
      "linear       ##qua       \n",
      "in           ##lities    \n",
      "##e          .           \n",
      "##qua        we          \n",
      "##lities     also        \n",
      ".            character   \n",
      "We           ##ize       \n",
      "also         the         \n",
      "character    fibers      \n",
      "##ize        of          \n",
      "the          the         \n",
      "fibers       corresponding\n",
      "of           mixture     \n",
      "the          map         \n",
      "corresponding .           \n",
      "mixture      in          \n",
      "map          addition    \n",
      ".            ,           \n",
      "In           we          \n",
      "addition     discuss     \n",
      ",            the         \n",
      "we           general     \n",
      "discuss      framework   \n",
      "the          of          \n",
      "general      tropical    \n",
      "framework    se          \n",
      "of           ##can       \n",
      "tropical     ##t         \n",
      "se           varieties   \n",
      "##can        and         \n",
      "##t          we          \n",
      "varieties    interpret   \n",
      "and          our         \n",
      "we           results     \n",
      "interpret    within      \n",
      "our          this        \n",
      "results      setting     \n",
      "within       .           \n",
      "this         finally     \n",
      "setting      ,           \n",
      ".            we          \n",
      "Finally      show        \n",
      ",            that        \n",
      "we           the         \n",
      "show         set         \n",
      "that         of          \n",
      "the          tree        \n",
      "set          metric      \n",
      "of           ranks       \n",
      "tree         of          \n",
      "metric       metric      \n",
      "ranks        ##s         \n",
      "of           on          \n",
      "metric       $           \n",
      "##s          n           \n",
      "on           $           \n",
      "$            taxa        \n",
      "n            is          \n",
      "$            un          \n",
      "taxa         ##bound     \n",
      "is           ##ed        \n",
      "un           .           \n",
      "##bound      comment     \n",
      "##ed         :           \n",
      ".            19          \n",
      "Co           pages       \n",
      "##mme        ,           \n",
      "##nt         5           \n",
      ":            figures     \n",
      "19           .           \n",
      "pages        major       \n",
      ",            revision    \n",
      "5            of          \n",
      "figures      the         \n",
      ".            exposition  \n",
      "Major        following   \n",
      "revision     suggestions \n",
      "of           by          \n",
      "the          the         \n",
      "exposition   referee     \n",
      "following    .           \n",
      "suggestions  to          \n",
      "by           appear      \n",
      "the          in          \n",
      "referee      an          \n",
      ".            ##nal       \n",
      "To           ##s         \n",
      "appear       of          \n",
      "in           comb        \n",
      "Annals       ##inator    \n",
      "of           ##ic        \n",
      "Co           paste       \n",
      "##mb         ##ure       \n",
      "##inator     ##llo       \n",
      "##ic         ##sis       \n",
      "Past         in          \n",
      "##eur        j           \n",
      "##ello       ##apa       \n",
      "##sis        ##nese      \n",
      "in           q           \n",
      "j            ##ua        \n",
      "##apa        ##il        \n",
      "##nese       (           \n",
      "q            co          \n",
      "##ua         ##turn      \n",
      "##il         ##ix        \n",
      "(            co          \n",
      "Co           ##turn      \n",
      "##turn       ##ix        \n",
      "##ix         j           \n",
      "co           ##apon      \n",
      "##turn       ##ica       \n",
      "##ix         )           \n",
      "j            caused      \n",
      "##apon       by          \n",
      "##ica        paste       \n",
      ")            ##ure       \n",
      "caused       ##lla       \n",
      "by           m           \n",
      "Past         ##ult       \n",
      "##eur        ##oc        \n",
      "##ella       ##ida       \n",
      "m            m           \n",
      "##ult        ##ult       \n",
      "##oc         ##oc        \n",
      "##ida        ##ida       \n",
      "m            a           \n",
      "##ult        :           \n",
      "##oc         4           \n",
      "##ida        .           \n",
      "A            nutrition   \n",
      ":            ##al        \n",
      "4            well        \n",
      ".            -           \n",
      "N            being       \n",
      "##UT         in          \n",
      "##RI         the         \n",
      "##TI         u           \n",
      "##ON         .           \n",
      "##AL         s           \n",
      "W            .           \n",
      "##EL         a           \n",
      "##L          .           \n",
      "-            counseling  \n",
      "B            professional\n",
      "##EI         nurses      \n",
      "##NG         .           \n",
      "IN           evaluation  \n",
      "THE          of          \n",
      "U            trans       \n",
      ".            ##der       \n",
      "S            ##mal       \n",
      ".            penetration \n",
      "A            enhance     \n",
      ".            ##rs        \n",
      "Counsel      using       \n",
      "##ing        a           \n",
      "professional novel       \n",
      "nurses       skin        \n",
      ".            alternative \n",
      "Evaluation   .           \n",
      "of           a           \n",
      "trans        novel       \n",
      "##der        alternative \n",
      "##mal        to          \n",
      "penetration  animal      \n",
      "enhance      skin        \n",
      "##rs         models      \n",
      "using        was         \n",
      "a            developed   \n",
      "novel        in          \n",
      "skin         order       \n",
      "alternative  to          \n",
      ".            aid         \n",
      "A            in          \n",
      "novel        the         \n",
      "alternative  screening   \n",
      "to           of          \n",
      "animal       trans       \n",
      "skin         ##der       \n",
      "models       ##mal       \n",
      "was          penetration \n",
      "developed    enhance     \n",
      "in           ##r         \n",
      "order        .           \n",
      "to           the         \n",
      "aid          skin        \n",
      "in           alternative \n",
      "the          consists    \n",
      "screening    of          \n",
      "of           a           \n",
      "trans        der         \n",
      "##der        ##mal       \n",
      "##mal        layer       \n",
      "penetration  containing  \n",
      "enhance      human       \n",
      "##r          fi          \n",
      ".            ##bro       \n",
      "The          ##blast     \n",
      "skin         ##s         \n",
      "alternative  dispersed   \n",
      "consists     in          \n",
      "of           a           \n",
      "a            co          \n",
      "der          ##lla       \n",
      "##mal        ##gen       \n",
      "layer        matrix      \n",
      "containing   and         \n",
      "human        an          \n",
      "fi           e           \n",
      "##bro        ##pid       \n",
      "##blast      ##er        \n",
      "##s          ##mal       \n",
      "dispersed    layer       \n",
      "in           of          \n",
      "a            differentiated\n",
      "co           and         \n",
      "##lla        s           \n",
      "##gen        ##tra       \n",
      "matrix       ##ti        \n",
      "and          ##fied      \n",
      "an           human       \n",
      "e            k           \n",
      "##pid        ##era       \n",
      "##er         ##tino      \n",
      "##mal        ##cy        \n",
      "layer        ##tes       \n",
      "of           .           \n",
      "differentiated             \n",
      "and                      \n",
      "s                        \n",
      "##tra                    \n",
      "##ti                     \n",
      "##fied                   \n",
      "human                    \n",
      "k                        \n",
      "##era                    \n",
      "##tino                   \n",
      "##cy                     \n",
      "##tes                    \n",
      ".                        \n"
     ]
    }
   ],
   "source": [
    "# Split the sentence into tokens, with both BERT and SciBERT.\n",
    "bert_tokens = bert_tokenizer.tokenize(text)\n",
    "med_tokens = med_tokenizer.tokenize(text)\n",
    "\n",
    "# Pad out the scibert list to be the same length.\n",
    "while len(med_tokens) < len(bert_tokens):\n",
    "    med_tokens.append(\"\")\n",
    "\n",
    "# Label the columns.\n",
    "print('{:<12} {:<12}'.format(\"BERT\", \"Med_BERT\"))\n",
    "print('{:<12} {:<12}'.format(\"----\", \"-------\"))\n",
    "\n",
    "# Display the tokens.\n",
    "for tup in zip(bert_tokens, med_tokens):\n",
    "    print('{:<12} {:<12}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb7935b20b1350c43bf64077ed6a04b20dae5a2fec5d0927cb7fd3126576106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
